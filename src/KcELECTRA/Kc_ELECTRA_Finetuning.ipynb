{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "\n",
    "path = str(pathlib.Path(os.path.abspath(\".\")).parent.parent)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2852,
     "status": "ok",
     "timestamp": 1762668979664,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "eXVeKnR4SzAp",
    "outputId": "6f44878f-637a-49fc-aece-ec0937d9934d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"{path}/data/processed/model/finetuning_preprocessed.txt\", sep=\"\\t\", names=['document', 'label'])\n",
    "# df\n",
    "print(df.columns)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1762669100586,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "gsDinbz6S2is",
    "outputId": "04f686eb-5e1b-449b-d651-72f0b6859ab2"
   },
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1762669104861,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "olr0TxymS6oE"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid = train_test_split(df, test_size=0.2, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30385,
     "status": "ok",
     "timestamp": 1762669136483,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "AWUeDv6Xuw0L"
   },
   "outputs": [],
   "source": [
    "# tokenizer 초기화\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer에 저장되어 있는 vocab.txt 파일을 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-small-v2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30751,
     "status": "ok",
     "timestamp": 1762669167238,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "yabDNb8nS-b_"
   },
   "outputs": [],
   "source": [
    "# tokenizing 및 tensordataset\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "def tokenize_function(df):\n",
    "    # tokenizing\n",
    "    # 문장을 모델이 처리하는 의미를 갖는 최소 단위로 토큰화 하고, 토큰화 된 단어들을 정수 인코딩\n",
    "\n",
    "    # 하나의 sequence가 가질 수 있는 최대 토큰의 갯수\n",
    "    # ex) 나는 밥을 먹었다. -> 4개의 토큰 + [CLS]문장의 시작, [SEP]문장의 끝 => 총 6개의 토큰\n",
    "    #     -> max_length=128이므로, 나머지 122개는 [PAD]패딩 토큰으로 채워짐\n",
    "    max_length = 128\n",
    "\n",
    "    # 1) 입력 받은 문장(df['document'])을 서브워드 단위로 분리(토큰화)\n",
    "    # 2) 분리된 서브워드를 로드된 단어 사전에서 찾아 해당 정수 인덱스로 변환(정수 인코딩)\n",
    "    # 3) 규칙에 따라 길이를 맞추고, input_ids와 attention_mask 생성\n",
    "    #       - input_ids : 텍스트를 모델이 이해할 수 있는 정수 인덱스로 변환한 값\n",
    "    #       - attention_mask : 실제 의미있는 토큰(1)/패딩 토큰(0)을 이진 분류하여 모델이 불필요한 계산을 하지 않도록 마스킹\n",
    "    encodings = tokenizer(\n",
    "        list(df['document']),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length = max_length\n",
    "    )\n",
    "\n",
    "    # dataset\n",
    "    # 모델에 입력된 모든 데이터를 tensor 객체로 저장하고 관리하는 저장소\n",
    "    #       - 데이터 통합 및 관리\n",
    "    #               여러 종류의 데이터를 동일한 인덱스로 묶어 데이터를 인덱스로 접근할 때 한 번에 출력할 수 있어 데이터 관리 용이\n",
    "\n",
    "    dataset = {\n",
    "        # x : 학습 데이터\n",
    "        'input_ids':encodings['input_ids'],\n",
    "        'attention_mask':encodings['attention_mask'],\n",
    "        # y : 레이블\n",
    "        'labels':df['label'].to_list()\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict(tokenize_function(train))\n",
    "valid_dataset = Dataset.from_dict(tokenize_function(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1762671050708,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "OcsEfplHkNSY",
    "outputId": "c02bf453-9fb7-4558-b223-a0302b5637a9"
   },
   "outputs": [],
   "source": [
    "# TrainingArguments\n",
    "\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if device==\"cpu\":\n",
    "    num_train_epochs=1\n",
    "    per_device_train_batch_size=2\n",
    "    gradient_accumulation_steps=8\n",
    "    dataloader_num_workers=0\n",
    "    dataloader_pin_memory=False\n",
    "\n",
    "elif device==\"cuda\":\n",
    "    num_train_epochs=3\n",
    "    per_device_train_batch_size=16\n",
    "    gradient_accumulation_steps=2\n",
    "    dataloader_num_workers=2\n",
    "    dataloader_pin_memory=True\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"{path}/model/KcELECTRA/finetuned/checkpoints\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "\n",
    "    logging_steps=50,\n",
    "\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "\n",
    "    dataloader_num_workers=dataloader_num_workers,\n",
    "    dataloader_pin_memory=dataloader_pin_memory,\n",
    "\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=False,\n",
    "\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=False,\n",
    "    hub_model_id=None,\n",
    "    hub_token=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1762671052471,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "c23xb2RrTFAA",
    "outputId": "db758db8-e4e7-46f5-88cc-d42ea3658202"
   },
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "\n",
    "from transformers import ElectraForSequenceClassification\n",
    "\n",
    "# KcELECTRA-small 모델로 finetuning\n",
    "model = ElectraForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-small-v2022\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 146,
     "status": "ok",
     "timestamp": 1762671053929,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "NCbeEojWTD0w"
   },
   "outputs": [],
   "source": [
    "# Trainer 설정\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1889458,
     "status": "ok",
     "timestamp": 1762672944249,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "FxSohUTKTGMF",
    "outputId": "d7ae507f-5182-43cb-b630-4c22dcd01420"
   },
   "outputs": [],
   "source": [
    "# 모델 학습\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 770,
     "status": "ok",
     "timestamp": 1762673068808,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "Hgz1SqXTmhBh",
    "outputId": "fb81fcea-b61f-419d-9c9b-94998a422e79"
   },
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "\n",
    "save_dir = f\"{path}/model/KcELECTRA/finetuned\"\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46280,
     "status": "ok",
     "timestamp": 1762673629815,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "maK6iunxYmHa",
    "outputId": "8232de65-83b9-48da-a8d7-020481da69d5"
   },
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# DataLoader 준비\n",
    "valid_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "eval_dataloader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
    "    labels = batch['labels'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "    all_preds.extend(preds.cpu().numpy())\n",
    "    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {acc*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1762673675796,
     "user": {
      "displayName": "jiyeon",
      "userId": "06315727781370043567"
     },
     "user_tz": -540
    },
    "id": "5nIc1Ym-TGnT",
    "outputId": "327ae407-e525-407d-c041-ffe2baea97ee"
   },
   "outputs": [],
   "source": [
    "# 예측 및 평가\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.eval()\n",
    "text = [\"이 영화 정말 재미있다\", \"별로였다\"]\n",
    "tokenizer.model_max_length = 128\n",
    "encoding = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(**encoding).logits\n",
    "    preds = logits.argmax(dim=-1)\n",
    "print(preds.cpu().numpy())  # [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9W2aENae1_mt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk5YE1ViDrEu/U/inSPK9R",
   "gpuType": "T4",
   "mount_file_id": "1hc9GTbVkN_A7EdvuWnRPYjbPriw3GxTy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Re_BERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
